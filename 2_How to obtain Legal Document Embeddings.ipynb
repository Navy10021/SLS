{"cells":[{"cell_type":"markdown","metadata":{"id":"h24hpRf2Rwij"},"source":["## 0. Import"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3vnPtRORRveR"},"outputs":[],"source":["! pip install transformers\n","! pip install -U sentence-transformers\n","! pip install sentencepiece"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-v-B08BVRy9R"},"outputs":[],"source":["from sentence_transformers import SentenceTransformer, SentencesDataset, LoggingHandler, losses, models, util\n","from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n","from sentence_transformers.readers import STSBenchmarkDataReader, InputExample\n","\n","import torch\n","from torch.utils.data import DataLoader\n","\n","import pandas as pd\n","import math\n","import sys\n","import logging"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1654507544398,"user":{"displayName":"Domingo Lee","userId":"09698896171274086367"},"user_tz":-540},"id":"TbE5ReX7R_c2","outputId":"4113b088-a967-44bb-ff36-dd5092d8c155"},"outputs":[{"name":"stdout","output_type":"stream","text":[">> Using cuda\n"]}],"source":["device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","print(\">> Using {}\".format(device))"]},{"cell_type":"markdown","metadata":{"id":"v85mtoc9fXdx"},"source":["## 1. Make Sentence-BERT from KoLawBERT"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"C1CREA6GoFOn"},"outputs":[],"source":["from models.kor_sentence_bert import *"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3090,"status":"ok","timestamp":1654507556305,"user":{"displayName":"Domingo Lee","userId":"09698896171274086367"},"user_tz":-540},"id":"itsbG8BSZ1si","outputId":"488d089a-2bda-4cd4-9241-8c25f4822b6f"},"outputs":[{"name":"stderr","output_type":"stream","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]}],"source":["# 1.Load BERT style Masking modeling\n","model_path=\"pretrained-KorLawDistil_2/checkpoint-11000\"\n","tokenizer_path=\"pretrained-KorLawDistil_2\"\n","model_name=\"bert\"\n","\n","# 2.Load Roberta style Masking modeling\n","model_path=\"pretrained-KorLawRoberta_2/checkpoint-7000\"\n","tokenizer_path=\"pretrained-KorLawRoberta_2\"\n","model_name=\"roberta\"\n","\n","# 3. Load ALBERT style Masking modeling\n","model_path=\"pretrained-KorLawAlBERT_2/checkpoint-5000\"\n","tokenizer_path=\"pretrained-KorLawAlBERT_2\"\n","model_name=\"albert\"\n","\n","# Make sentence BERT\n","model = make_sentenceBERT(model_path=model_path,\n","                          tokenizer_path=tokenizer_path,\n","                          model_name=model_name,\n","                          device=device)"]},{"cell_type":"markdown","metadata":{"id":"y-W779KchQof"},"source":["## 2. KorNLI Fine-Tuning Task"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4706,"status":"ok","timestamp":1654507661323,"user":{"displayName":"Domingo Lee","userId":"09698896171274086367"},"user_tz":-540},"id":"WbwyEaiNgql6","outputId":"81ee9894-1531-44dc-a957-e29772546b4f"},"outputs":[{"name":"stdout","output_type":"stream","text":[">> Total Train Dataset size : 942854\n",">> Total Validataion Dataset size : 1500\n",">> Total Test Dataset size : 1379\n"]}],"source":["# Dataset for Train\n","train_snli = pd.read_csv(\"../S_bert/data/snli_1.0_train.ko.tsv\", sep='\\t', quoting=3)  # quating = 3 : 큰 따옴표 무시\n","train_xnli = pd.read_csv(\"../S_bert/data/multinli.train.ko.tsv\", sep='\\t', quoting=3)\n","train_data = pd.concat([train_snli, train_xnli], ignore_index=True)\n","print(\">> Total Train Dataset size :\", len(train_data))\n","\n","# Dataset for Eval\n","val_data = pd.read_csv(\"../S_bert/data/sts-dev.tsv\", sep='\\t', quoting=3)\n","test_data = pd.read_csv(\"../S_bert/data/sts-test.tsv\", sep='\\t', quoting=3)\n","print(\">> Total Validataion Dataset size :\", len(val_data))\n","print(\">> Total Test Dataset size :\", len(test_data))\n","\n","# label_dict\n","label_dict = {\"contradiction\": 0, \"entailment\": 1, \"neutral\": 2}"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":1408,"status":"ok","timestamp":1654507674384,"user":{"displayName":"Domingo Lee","userId":"09698896171274086367"},"user_tz":-540},"id":"8FEYvo8kQK5r","outputId":"ca9f2cdb-60f1-4a83-c9aa-8d9c2cf5c15f"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-462e2c66-f865-415c-8269-7813cddefc39\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sentence1</th>\n","      <th>sentence2</th>\n","      <th>gold_label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>말을 탄 사람이 고장난 비행기 위로 뛰어오른다.</td>\n","      <td>한 사람이 경쟁을 위해 말을 훈련시키고 있다.</td>\n","      <td>neutral</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>말을 탄 사람이 고장난 비행기 위로 뛰어오른다.</td>\n","      <td>한 사람이 식당에서 오믈렛을 주문하고 있다.</td>\n","      <td>contradiction</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>말을 탄 사람이 고장난 비행기 위로 뛰어오른다.</td>\n","      <td>사람은 야외에서 말을 타고 있다.</td>\n","      <td>entailment</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>카메라에 웃고 손을 흔드는 아이들</td>\n","      <td>그들은 부모님을 보고 웃고 있다</td>\n","      <td>neutral</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>카메라에 웃고 손을 흔드는 아이들</td>\n","      <td>아이들이 있다</td>\n","      <td>entailment</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-462e2c66-f865-415c-8269-7813cddefc39')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-462e2c66-f865-415c-8269-7813cddefc39 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-462e2c66-f865-415c-8269-7813cddefc39');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                    sentence1                  sentence2     gold_label\n","0  말을 탄 사람이 고장난 비행기 위로 뛰어오른다.  한 사람이 경쟁을 위해 말을 훈련시키고 있다.        neutral\n","1  말을 탄 사람이 고장난 비행기 위로 뛰어오른다.   한 사람이 식당에서 오믈렛을 주문하고 있다.  contradiction\n","2  말을 탄 사람이 고장난 비행기 위로 뛰어오른다.         사람은 야외에서 말을 타고 있다.     entailment\n","3          카메라에 웃고 손을 흔드는 아이들          그들은 부모님을 보고 웃고 있다        neutral\n","4          카메라에 웃고 손을 흔드는 아이들                    아이들이 있다     entailment"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["train_data = drop_kornli(train_data)\n","train_data.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vBEj2aKCQ-xo"},"outputs":[],"source":["# Make Dataset for Training\n","# Traing dataset\n","train_batch_size = 16\n","train_samples = make_kornli_dataset(train_data)\n","\n","# Train DataLoader\n","train_dataset = SentencesDataset(train_samples, model)\n","train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=train_batch_size)\n","\n","# Val/Test dataset\n","val_data = drop_korsts(val_data)\n","test_data = drop_korsts(test_data)\n","\n","dev_samples = make_korsts_dataset(val_data)\n","test_samples = make_korsts_dataset(test_data)\n","\n","# Eval DataLoader\n","dev_evaluator = EmbeddingSimilarityEvaluator.from_input_examples(dev_samples, batch_size=train_batch_size, name='sts-dev')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Wd6dGGiFjnS3"},"outputs":[],"source":["# Loss function : Calculate MSE loss\n","train_loss = losses.SoftmaxLoss(model=model,\n","                                sentence_embedding_dimension=model.get_sentence_embedding_dimension(),\n","                                num_labels=len(label_dict))\n","\n","# Warmup(10% of train data for warm-up) & Epochs\n","num_epochs = 3\n","warmup_steps = math.ceil(len(train_dataset) * num_epochs / train_batch_size * 0.1)   \n","logging.info(\"Warmup-steps: {}\".format(warmup_steps))"]},{"cell_type":"markdown","metadata":{"id":"UGYFmL5PfGJZ"},"source":["### 2-1. Train"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tOh-iClijqqA"},"outputs":[],"source":["#model_save_path = 'output/nil_task_bert'\n","model_save_path = 'output/nil_task_albert'\n","#model_save_path = 'output/nil_task_roberta'\n","\n","\n","model.fit(train_objectives=[(train_dataloader, train_loss)],\n","          evaluator=dev_evaluator,\n","          epochs=num_epochs,\n","          evaluation_steps=1000,\n","          warmup_steps=warmup_steps,\n","          output_path=model_save_path)"]},{"cell_type":"markdown","metadata":{"id":"1Az53lpAkFe8"},"source":["### 2-2. Evaluation"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2707,"status":"ok","timestamp":1653539972559,"user":{"displayName":"Domingo Lee","userId":"09698896171274086367"},"user_tz":-540},"id":"igoqrV_fkIZo","outputId":"0ff24ea8-5042-4128-ffec-736f27589d0b"},"outputs":[{"name":"stderr","output_type":"stream","text":["WARNING:root:No sentence-transformers model found with name output/nil_law/0_Transformer. Creating a new one with MEAN pooling.\n"]},{"name":"stdout","output_type":"stream","text":[">> Best TEST Score is : 0.6405\n"]}],"source":["model_save_path = 'output/nil_task_bert/0_Transformer'\n","model = SentenceTransformer(model_save_path)\n","test_evaluator = EmbeddingSimilarityEvaluator.from_input_examples(test_samples, batch_size=train_batch_size, name='sts-test')\n","print(\">> Best TEST Score is : {:.4f}\".format(test_evaluator(model, output_path=model_save_path)))"]},{"cell_type":"markdown","metadata":{"id":"k532X54neB8w"},"source":["## 3. KorSTS Fine-Tuning Task"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5778,"status":"ok","timestamp":1653974495822,"user":{"displayName":"Domingo Lee","userId":"09698896171274086367"},"user_tz":-540},"id":"poTVW4Z4jBM2","outputId":"9da98dad-e04d-4aed-9252-0a6519673380"},"outputs":[{"name":"stdout","output_type":"stream","text":[">> Using cpu\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:root:No sentence-transformers model found with name output/nil_law/0_Transformer. Creating a new one with MEAN pooling.\n"]}],"source":["device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","print(\">> Using {}\".format(device))\n","\n","# NLI TASK : Trained Distilation(5 epoch)\n","model_name = 'output/nil_law/0_Transformer'\n","model_save_path = 'output/sts_law'\n","# Load Model\n","model = SentenceTransformer(model_name)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pG8wdJ7SSqZU"},"outputs":[],"source":["# Get KoSTS Dataset(made by Kakao Brain)\n","train_data = pd.read_csv(\"../S_bert/data/sts-train.tsv\", sep='\\t', quoting=3)\n","val_data = pd.read_csv(\"../S_bert/data/sts-dev.tsv\", sep='\\t', quoting=3)\n","test_data = pd.read_csv(\"../S_bert/data/sts-test.tsv\", sep='\\t', quoting=3)\n","\n","train_data = drop_korsts(train_data)\n","val_data = drop_korsts(val_data)\n","test_data = drop_korsts(test_data)\n","\n","# Traing/val/test dataset\n","train_samples = make_korsts_dataset(train_data)\n","dev_samples = make_korsts_dataset(val_data)\n","test_samples = make_korsts_dataset(test_data)\n","\n","# DataLoader\n","train_dataset = SentencesDataset(train_samples, model)\n","train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=train_batch_size)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9dFHctvJjWqP"},"outputs":[],"source":["# Loss function : Calculate Cosine similarity\n","train_loss = losses.CosineSimilarityLoss(model=model)\n","\n","# Evaluator \n","evaluator = EmbeddingSimilarityEvaluator.from_input_examples(dev_samples, name='sts-dev')\n","\n","# Warmup(10% of train data for warm-up) & Epochs\n","num_epochs = 10\n","warmup_steps = math.ceil(len(train_dataset) * num_epochs / train_batch_size * 0.1)  \n","logging.info(\"Warmup-steps: {}\".format(warmup_steps))"]},{"cell_type":"markdown","metadata":{"id":"z7KVXxuFjgyd"},"source":["### 3-1. Train"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RJuyroo5jiG9"},"outputs":[],"source":["model.fit(train_objectives=[(train_dataloader, train_loss)],\n","          evaluator=evaluator,\n","          epochs=num_epochs,\n","          evaluation_steps=1000,\n","          warmup_steps=warmup_steps,\n","          output_path=model_save_path)"]},{"cell_type":"markdown","metadata":{"id":"LB7dEZfijkE2"},"source":["### 3-2. Evaluation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bpmj6rnzjlf1"},"outputs":[],"source":["model_save_path = 'output/sts_law'\n","print(\">> Trained BERT Model Name is :\", model_save_path)\n","model = SentenceTransformer(model_save_path)\n","\n","test_evaluator = EmbeddingSimilarityEvaluator.from_input_examples(test_samples, name='sts-test')\n","print(\">> Best TEST Socre is : {:.4f}\".format(test_evaluator(model, output_path=model_save_path)))"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyOca9M0CJnQ3VlbtJ4p90QK","collapsed_sections":[],"name":"2_Legal Document Embeddings.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
