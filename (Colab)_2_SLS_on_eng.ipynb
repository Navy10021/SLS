{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyN/T0uRDBFg9JsMdU+knswx"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard","widgets":{"application/vnd.jupyter.widget-state+json":{"a3a487414d674d5c8d59d9482a854594":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0248a82d5f7d429e9053c6ea741c81f5","IPY_MODEL_7379758179544631bb8ec63a6260ba6d","IPY_MODEL_45b0e55023a14821a12dd82ea9840bd3"],"layout":"IPY_MODEL_b1cb099577114a63b1ce11cfd6244776"}},"0248a82d5f7d429e9053c6ea741c81f5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8b8728c5a343426694ee3a501caa6cbd","placeholder":"​","style":"IPY_MODEL_bd6bb7efcc9f4892b88253e2e3c63d58","value":"Batches: 100%"}},"7379758179544631bb8ec63a6260ba6d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_570ddf72b5e8490aa747ef96ee0b4c32","max":595,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3a5d1905c6374e53987e32e69d4a1cbf","value":595}},"45b0e55023a14821a12dd82ea9840bd3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_364e8f4d5f544751a0b7d3e7e53ee3e5","placeholder":"​","style":"IPY_MODEL_a16956cc8a4948c98e801a86acfc3f9e","value":" 595/595 [00:42&lt;00:00, 13.64it/s]"}},"b1cb099577114a63b1ce11cfd6244776":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8b8728c5a343426694ee3a501caa6cbd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bd6bb7efcc9f4892b88253e2e3c63d58":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"570ddf72b5e8490aa747ef96ee0b4c32":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3a5d1905c6374e53987e32e69d4a1cbf":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"364e8f4d5f544751a0b7d3e7e53ee3e5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a16956cc8a4948c98e801a86acfc3f9e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["# ACL 2023\n","## Semantic Legal Searcher(SLS) on the English dataset"],"metadata":{"id":"pQVmIMf4Zz9D"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"t9CiAhbP2ACP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670587234383,"user_tz":-540,"elapsed":22124,"user":{"displayName":"yoon-seop Lee","userId":"09698896171274086367"}},"outputId":"7f4dac20-3695-41ad-e67f-2f1ea06efe3b"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["cd /content/drive/MyDrive/ACL_2023_SLS/"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eKW5z95pZ7N3","executionInfo":{"status":"ok","timestamp":1670587234383,"user_tz":-540,"elapsed":6,"user":{"displayName":"yoon-seop Lee","userId":"09698896171274086367"}},"outputId":"e4bd24a8-cafc-4be4-9b6c-3a05c9a61f50"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/ACL_2023_SLS\n"]}]},{"cell_type":"markdown","source":["## PIP"],"metadata":{"id":"8a3aYrCR0FMn"}},{"cell_type":"code","source":["! pip install transformers\n","! pip install -U sentence-transformers\n","! pip install sentencepiece\n","! pip install faiss-gpu\n","! pip install funcy pickle5"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"191HUmzLZ8yb","executionInfo":{"status":"ok","timestamp":1670587278321,"user_tz":-540,"elapsed":43941,"user":{"displayName":"yoon-seop Lee","userId":"09698896171274086367"}},"outputId":"a66f5bf6-6003-4b9d-ea56-71f06e28c76b"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.25.1-py3-none-any.whl (5.8 MB)\n","\u001b[K     |████████████████████████████████| 5.8 MB 32.9 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.8.0)\n","Collecting huggingface-hub<1.0,>=0.10.0\n","  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n","\u001b[K     |████████████████████████████████| 182 kB 77.0 MB/s \n","\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n","  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n","\u001b[K     |████████████████████████████████| 7.6 MB 54.8 MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.9.24)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.11.1 tokenizers-0.13.2 transformers-4.25.1\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting sentence-transformers\n","  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n","\u001b[K     |████████████████████████████████| 85 kB 262 kB/s \n","\u001b[?25hRequirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.8/dist-packages (from sentence-transformers) (4.25.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from sentence-transformers) (4.64.1)\n","Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from sentence-transformers) (1.13.0+cu116)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.8/dist-packages (from sentence-transformers) (0.14.0+cu116)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from sentence-transformers) (1.21.6)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (from sentence-transformers) (1.0.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from sentence-transformers) (1.7.3)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.8/dist-packages (from sentence-transformers) (3.7)\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.97-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[K     |████████████████████████████████| 1.3 MB 56.0 MB/s \n","\u001b[?25hRequirement already satisfied: huggingface-hub>=0.4.0 in /usr/local/lib/python3.8/dist-packages (from sentence-transformers) (0.11.1)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (21.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.4.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.8.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.23.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (6.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.9->huggingface-hub>=0.4.0->sentence-transformers) (3.0.9)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2022.6.2)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.13.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from nltk->sentence-transformers) (1.2.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from nltk->sentence-transformers) (7.1.2)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2022.9.24)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->sentence-transformers) (3.1.0)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.8/dist-packages (from torchvision->sentence-transformers) (7.1.2)\n","Building wheels for collected packages: sentence-transformers\n","  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125938 sha256=2141576dd34811180cf39bb6de90f322cc05eb69f1e1853b9dbee888ac0ea42c\n","  Stored in directory: /root/.cache/pip/wheels/5e/6f/8c/d88aec621f3f542d26fac0342bef5e693335d125f4e54aeffe\n","Successfully built sentence-transformers\n","Installing collected packages: sentencepiece, sentence-transformers\n","Successfully installed sentence-transformers-2.2.2 sentencepiece-0.1.97\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.8/dist-packages (0.1.97)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting faiss-gpu\n","  Downloading faiss_gpu-1.7.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (85.5 MB)\n","\u001b[K     |████████████████████████████████| 85.5 MB 84 kB/s \n","\u001b[?25hInstalling collected packages: faiss-gpu\n","Successfully installed faiss-gpu-1.7.2\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting funcy\n","  Downloading funcy-1.17-py2.py3-none-any.whl (33 kB)\n","Collecting pickle5\n","  Downloading pickle5-0.0.11.tar.gz (132 kB)\n","\u001b[K     |████████████████████████████████| 132 kB 61.4 MB/s \n","\u001b[?25hBuilding wheels for collected packages: pickle5\n","  Building wheel for pickle5 (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pickle5: filename=pickle5-0.0.11-cp38-cp38-linux_x86_64.whl size=236284 sha256=e8dacd4850ae55c8d7467d388036d7df0bddd8148588266e1b4655f256746b54\n","  Stored in directory: /root/.cache/pip/wheels/25/d4/61/dbd8edd1a0d656be7b4267c85db3b61951eb60016a0154a122\n","Successfully built pickle5\n","Installing collected packages: pickle5, funcy\n","Successfully installed funcy-1.17 pickle5-0.0.11\n"]}]},{"cell_type":"markdown","source":["## STEP1. Load arxiv dataset & PLMs (ENG)"],"metadata":{"id":"UJykzVv0aAEQ"}},{"cell_type":"code","source":["import pandas as pd\n","import json\n","\n","# 1. Load arxiv-abstract meta data \n","data_file = './data/arxiv-metadata-oai-snapshot.json'\n","\n","def get_metadata():\n","    with open(data_file, 'r') as f:\n","        for line in f:\n","            yield line\n","\n","metadata = get_metadata()\n","for paper in metadata:\n","    paper_dict = json.loads(paper)\n","    print('Title: {}\\n\\nAbstract: {}\\nRef: {}'.format(paper_dict.get('title'), paper_dict.get('abstract'), paper_dict.get('journal-ref')))\n","    break\n","\n","titles, abstracts, years = [], [], []\n","metadata = get_metadata()\n","for paper in metadata:\n","    paper_dict = json.loads(paper)\n","    ref = paper_dict.get('journal-ref')\n","    try:\n","        year = int(ref[-4:]) \n","        if 2016 < year < 2021:\n","            years.append(year)\n","            titles.append(paper_dict.get('title'))\n","            abstracts.append(paper_dict.get('abstract'))\n","    except:\n","        pass\n","\n","# 2. Make DataFrame\n","papers = pd.DataFrame({\n","    'title': titles,\n","    'abstract': abstracts,\n","    'year': years\n","})\n","\n","papers.to_csv('./data/arxiv_meta.csv', sep = ',', na_rep=\"NaN\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ngM26BpoZ_EA","executionInfo":{"status":"ok","timestamp":1670571524279,"user_tz":-540,"elapsed":72700,"user":{"displayName":"yoon-seop Lee","userId":"09698896171274086367"}},"outputId":"35bcb49c-9cc9-4c38-ec4a-e81f5cf37696"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Title: Calculation of prompt diphoton production cross sections at Tevatron and\n","  LHC energies\n","\n","Abstract:   A fully differential calculation in perturbative quantum chromodynamics is\n","presented for the production of massive photon pairs at hadron colliders. All\n","next-to-leading order perturbative contributions from quark-antiquark,\n","gluon-(anti)quark, and gluon-gluon subprocesses are included, as well as\n","all-orders resummation of initial-state gluon radiation valid at\n","next-to-next-to-leading logarithmic accuracy. The region of phase space is\n","specified in which the calculation is most reliable. Good agreement is\n","demonstrated with data from the Fermilab Tevatron, and predictions are made for\n","more detailed tests with CDF and DO data. Predictions are shown for\n","distributions of diphoton pairs produced at the energy of the Large Hadron\n","Collider (LHC). Distributions of the diphoton pairs from the decay of a Higgs\n","boson are contrasted with those produced from QCD processes at the LHC, showing\n","that enhanced sensitivity to the signal can be obtained with judicious\n","selection of events.\n","\n","Ref: Phys.Rev.D76:013009,2007\n"]}]},{"cell_type":"code","source":["# 1. Load arXiv dataset(Cornell University., 2022)\n","df = pd.read_csv('./data/arxiv_meta.csv')\n","print(\">> arxiv-meta data size : \", len(df))\n","\n","# 2. Load pre-trained language model on English dataset\n","my_plms = \"all-mpnet-base-v2\"\n","df.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":225},"id":"YW1Q-mzhzNX1","executionInfo":{"status":"ok","timestamp":1670587279718,"user_tz":-540,"elapsed":1403,"user":{"displayName":"yoon-seop Lee","userId":"09698896171274086367"}},"outputId":"7a1a4e6d-d77d-4b3f-f42a-1f07fe1bd059"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":[">> arxiv-meta data size :  19035\n"]},{"output_type":"execute_result","data":{"text/plain":["   Unnamed: 0                                              title  \\\n","0           0  On the Cohomological Derivation of Yang-Mills ...   \n","1           1  Regularity of solutions of the isoperimetric p...   \n","2           2  Asymptotic theory of least squares estimators ...   \n","3           3  Teichm\\\"uller Structures and Dual Geometric Gi...   \n","4           4  Distributional Schwarzschild Geometry from non...   \n","\n","                                            abstract  year  \n","0    We present a brief review of the cohomologic...  2017  \n","1    In this work we consider a question in the c...  2018  \n","2    This paper considers the effect of least squ...  2017  \n","3    The Gibbs measure theory for smooth potentia...  2020  \n","4    In this paper we leave the neighborhood of t...  2018  "],"text/html":["\n","  <div id=\"df-32261a65-b99e-444d-a18d-5f1de616c224\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>title</th>\n","      <th>abstract</th>\n","      <th>year</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>On the Cohomological Derivation of Yang-Mills ...</td>\n","      <td>We present a brief review of the cohomologic...</td>\n","      <td>2017</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>Regularity of solutions of the isoperimetric p...</td>\n","      <td>In this work we consider a question in the c...</td>\n","      <td>2018</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>Asymptotic theory of least squares estimators ...</td>\n","      <td>This paper considers the effect of least squ...</td>\n","      <td>2017</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>Teichm\\\"uller Structures and Dual Geometric Gi...</td>\n","      <td>The Gibbs measure theory for smooth potentia...</td>\n","      <td>2020</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>Distributional Schwarzschild Geometry from non...</td>\n","      <td>In this paper we leave the neighborhood of t...</td>\n","      <td>2018</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-32261a65-b99e-444d-a18d-5f1de616c224')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-32261a65-b99e-444d-a18d-5f1de616c224 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-32261a65-b99e-444d-a18d-5f1de616c224');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":6}]},{"cell_type":"markdown","source":["## STEP 2. Parallel Clustering-based Topic Modeling"],"metadata":{"id":"13_Z_2iIzaAE"}},{"cell_type":"code","source":["from models.parallel_clustering_TM import *"],"metadata":{"id":"hd822jmkz78o","executionInfo":{"status":"ok","timestamp":1670587289955,"user_tz":-540,"elapsed":10250,"user":{"displayName":"yoon-seop Lee","userId":"09698896171274086367"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["# 1. Obtain Embeddings\n","target_text = 'abstract'\n","\n","cluster = ParallelCluster(\n","    dataframe = df,\n","    tgt_col = target_text,\n","    model_name = my_plms,\n","    use_sentence_bert = True\n","    )"],"metadata":{"id":"7WYk1qlKz7_R"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 2. Parallel Clustering\n","clusters, unclusters = cluster.parallel_cluster(\n","    clusters = None,\n","    threshold = 0.56,\n","    page_size = 2000,\n","    iterations = 30\n","    )"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ijF9jOT31uZj","executionInfo":{"status":"ok","timestamp":1670587878975,"user_tz":-540,"elapsed":22766,"user":{"displayName":"yoon-seop Lee","userId":"09698896171274086367"}},"outputId":"7ba4fba0-549e-4772-b56e-eba179d332f6"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["===== Iteration 1 / 30 =====\n","\n","\n",">> Number of Total Clusters :  429\n",">> Percentage clusted Doc Embeddings : 38.92%\n","\n","\n","===== Iteration 2 / 30 =====\n","\n","\n",">> Number of Total Clusters :  839\n",">> Percentage clusted Doc Embeddings : 58.91%\n","\n","\n","===== Iteration 3 / 30 =====\n","\n","\n",">> Number of Total Clusters :  1125\n",">> Percentage clusted Doc Embeddings : 67.89%\n","\n","\n","===== Iteration 4 / 30 =====\n","\n","\n",">> Number of Total Clusters :  1245\n",">> Percentage clusted Doc Embeddings : 70.77%\n","\n","\n","===== Iteration 5 / 30 =====\n","\n","\n",">> Number of Total Clusters :  1356\n",">> Percentage clusted Doc Embeddings : 73.15%\n","\n","\n","===== Iteration 6 / 30 =====\n","\n","\n",">> Number of Total Clusters :  1414\n",">> Percentage clusted Doc Embeddings : 74.25%\n","\n","\n","===== Iteration 7 / 30 =====\n","\n","\n",">> Number of Total Clusters :  1474\n",">> Percentage clusted Doc Embeddings : 75.31%\n","\n","\n","===== Iteration 8 / 30 =====\n","\n","\n",">> Number of Total Clusters :  1510\n",">> Percentage clusted Doc Embeddings : 75.99%\n","\n","\n","===== Iteration 9 / 30 =====\n","\n","\n",">> Number of Total Clusters :  1536\n",">> Percentage clusted Doc Embeddings : 76.43%\n","\n","\n","===== Iteration 10 / 30 =====\n","\n","\n",">> Number of Total Clusters :  1556\n",">> Percentage clusted Doc Embeddings : 76.75%\n","\n","\n","===== Iteration 11 / 30 =====\n","\n","\n",">> Number of Total Clusters :  1575\n",">> Percentage clusted Doc Embeddings : 77.07%\n","\n","\n","===== Iteration 12 / 30 =====\n","\n","\n",">> Number of Total Clusters :  1588\n",">> Percentage clusted Doc Embeddings : 77.29%\n","\n","\n","===== Iteration 13 / 30 =====\n","\n","\n",">> Number of Total Clusters :  1596\n",">> Percentage clusted Doc Embeddings : 77.42%\n","\n","\n","===== Iteration 14 / 30 =====\n","\n","\n",">> Number of Total Clusters :  1608\n",">> Percentage clusted Doc Embeddings : 77.61%\n","\n","\n","===== Iteration 15 / 30 =====\n","\n","\n",">> Number of Total Clusters :  1628\n",">> Percentage clusted Doc Embeddings : 77.93%\n","\n","\n","===== Iteration 16 / 30 =====\n","\n","\n",">> Number of Total Clusters :  1638\n",">> Percentage clusted Doc Embeddings : 78.09%\n","\n","\n","===== Iteration 17 / 30 =====\n","\n","\n",">> Number of Total Clusters :  1647\n",">> Percentage clusted Doc Embeddings : 78.23%\n","\n","\n","===== Iteration 18 / 30 =====\n","\n","\n",">> Number of Total Clusters :  1656\n",">> Percentage clusted Doc Embeddings : 78.38%\n","\n","\n","===== Iteration 19 / 30 =====\n","\n","\n",">> Number of Total Clusters :  1659\n",">> Percentage clusted Doc Embeddings : 78.43%\n","\n","\n","===== Iteration 20 / 30 =====\n","\n","\n",">> Number of Total Clusters :  1664\n",">> Percentage clusted Doc Embeddings : 78.51%\n","\n","\n","===== Iteration 21 / 30 =====\n","\n","\n",">> Number of Total Clusters :  1669\n",">> Percentage clusted Doc Embeddings : 78.59%\n","\n","\n","===== Iteration 22 / 30 =====\n","\n","\n",">> Number of Total Clusters :  1671\n",">> Percentage clusted Doc Embeddings : 78.62%\n","\n","\n","===== Iteration 23 / 30 =====\n","\n","\n",">> Number of Total Clusters :  1673\n",">> Percentage clusted Doc Embeddings : 78.65%\n","\n","\n","===== Iteration 24 / 30 =====\n","\n","\n",">> Number of Total Clusters :  1675\n",">> Percentage clusted Doc Embeddings : 78.68%\n","\n","\n","===== Iteration 25 / 30 =====\n","\n","\n",">> Precautions! Reduce the number of Iterations or the Threshold!\n",">> Number of Total Clusters :  1675\n",">> Percentage clusted Doc Embeddings : 78.68%\n","\n","\n","===== Iteration 26 / 30 =====\n","\n","\n",">> Number of Total Clusters :  1678\n",">> Percentage clusted Doc Embeddings : 78.73%\n","\n","\n","===== Iteration 27 / 30 =====\n","\n","\n",">> Precautions! Reduce the number of Iterations or the Threshold!\n",">> Number of Total Clusters :  1678\n",">> Percentage clusted Doc Embeddings : 78.73%\n","\n","\n","===== Iteration 28 / 30 =====\n","\n","\n",">> Number of Total Clusters :  1679\n",">> Percentage clusted Doc Embeddings : 78.74%\n","\n","\n","===== Iteration 29 / 30 =====\n","\n","\n",">> Number of Total Clusters :  1685\n",">> Percentage clusted Doc Embeddings : 78.84%\n","\n","\n","===== Iteration 30 / 30 =====\n","\n","\n",">> Precautions! Reduce the number of Iterations or the Threshold!\n",">> Number of Total Clusters :  1685\n",">> Percentage clusted Doc Embeddings : 78.84%\n","\n","\n"]}]},{"cell_type":"code","source":["# 3. Stack : Stack the clustered results in order of cluster size\n","col_list = ['title', 'abstract', 'year']\n","new_df = cluster.cluster_stack(\n","    col_list = col_list,\n","    clusters = clusters,\n","    unclusters = unclusters\n","    )\n","\n","# 4. Extract Keywords from each documents\n","top_n_words = cluster.extract_top_n_words_per_topic(\n","    dataframe = new_df,\n","    n = 20,\n","    en = True\n","    )\n","new_df['keywords'] = [', '.join(top_n_words[i]) for i in new_df['Topic'].values]\n","\n","# 5. Save the Parallel Clusted Dataset \n","new_df.to_csv(\"./data/clusted_arxiv_df.csv\", sep=',', na_rep=\"NaN\")"],"metadata":{"id":"KUOyU1us2C9Q","executionInfo":{"status":"ok","timestamp":1670587905998,"user_tz":-540,"elapsed":14098,"user":{"displayName":"yoon-seop Lee","userId":"09698896171274086367"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["new_df.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":337},"id":"b6PS1HGr3DP4","executionInfo":{"status":"ok","timestamp":1670587905998,"user_tz":-540,"elapsed":21,"user":{"displayName":"yoon-seop Lee","userId":"09698896171274086367"}},"outputId":"da3d278f-a9c0-4d42-b980-0b142a57329d"},"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                  title  \\\n","890   Testing the anisotropy in the angular distribu...   \n","1228  Solving the missing GRB neutrino and GRB-SN pu...   \n","1518  Simulating galaxy formation with black hole dr...   \n","1874  High energy properties of the flat spectrum ra...   \n","1980  Nearest Neighbor: The Low-Mass Milky Way Satel...   \n","\n","                                               abstract  year  Topic  \\\n","890     Gamma-ray bursts (GRBs) were confirmed to be...  2017      0   \n","1228    Every GRB model where the progenitor is assu...  2018      0   \n","1518    The inefficiency of star formation in massiv...  2017      0   \n","1874    We investigate the $\\gamma$-ray and X-ray pr...  2018      0   \n","1980    We present Magellan/IMACS spectroscopy of th...  2017      0   \n","\n","                                               keywords  \n","890   ray, emission, gamma, star, 10, mass, luminosi...  \n","1228  ray, emission, gamma, star, 10, mass, luminosi...  \n","1518  ray, emission, gamma, star, 10, mass, luminosi...  \n","1874  ray, emission, gamma, star, 10, mass, luminosi...  \n","1980  ray, emission, gamma, star, 10, mass, luminosi...  "],"text/html":["\n","  <div id=\"df-f21caf22-1b22-4579-9ecb-95ffd7fcd521\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>title</th>\n","      <th>abstract</th>\n","      <th>year</th>\n","      <th>Topic</th>\n","      <th>keywords</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>890</th>\n","      <td>Testing the anisotropy in the angular distribu...</td>\n","      <td>Gamma-ray bursts (GRBs) were confirmed to be...</td>\n","      <td>2017</td>\n","      <td>0</td>\n","      <td>ray, emission, gamma, star, 10, mass, luminosi...</td>\n","    </tr>\n","    <tr>\n","      <th>1228</th>\n","      <td>Solving the missing GRB neutrino and GRB-SN pu...</td>\n","      <td>Every GRB model where the progenitor is assu...</td>\n","      <td>2018</td>\n","      <td>0</td>\n","      <td>ray, emission, gamma, star, 10, mass, luminosi...</td>\n","    </tr>\n","    <tr>\n","      <th>1518</th>\n","      <td>Simulating galaxy formation with black hole dr...</td>\n","      <td>The inefficiency of star formation in massiv...</td>\n","      <td>2017</td>\n","      <td>0</td>\n","      <td>ray, emission, gamma, star, 10, mass, luminosi...</td>\n","    </tr>\n","    <tr>\n","      <th>1874</th>\n","      <td>High energy properties of the flat spectrum ra...</td>\n","      <td>We investigate the $\\gamma$-ray and X-ray pr...</td>\n","      <td>2018</td>\n","      <td>0</td>\n","      <td>ray, emission, gamma, star, 10, mass, luminosi...</td>\n","    </tr>\n","    <tr>\n","      <th>1980</th>\n","      <td>Nearest Neighbor: The Low-Mass Milky Way Satel...</td>\n","      <td>We present Magellan/IMACS spectroscopy of th...</td>\n","      <td>2017</td>\n","      <td>0</td>\n","      <td>ray, emission, gamma, star, 10, mass, luminosi...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f21caf22-1b22-4579-9ecb-95ffd7fcd521')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-f21caf22-1b22-4579-9ecb-95ffd7fcd521 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-f21caf22-1b22-4579-9ecb-95ffd7fcd521');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":14}]},{"cell_type":"markdown","source":["## STEP 3. Embedding modelization(split-merge) and scoring(multi-interactions)"],"metadata":{"id":"d8cWnQFo3LGt"}},{"cell_type":"code","source":["from models.semantic_searcher_eng import *"],"metadata":{"id":"NfyrWmY03Ein","executionInfo":{"status":"ok","timestamp":1670587911701,"user_tz":-540,"elapsed":1776,"user":{"displayName":"yoon-seop Lee","userId":"09698896171274086367"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["# 1. Load SLS framework\n","sls = SLS(\n","    dataframe = new_df,\n","    doc_col = 'abstract',\n","    key_col = 'keywords',\n","    model_name = my_plms,\n","    use_sentence_bert = True,\n","    split_and_merge = True,\n","    multi_inter = True,\n","    )\n","\n","# 2. Build the Index\n","# (Strategy 1) : All Distance Metric\n","all_index = sls.all_distance_metric()\n","# (Strategy 2) : Restricted Distance Metric\n","#restricted_index = sls.restricted_distance_metric(nlist = 200, nprobe = 6)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":86,"referenced_widgets":["a3a487414d674d5c8d59d9482a854594","0248a82d5f7d429e9053c6ea741c81f5","7379758179544631bb8ec63a6260ba6d","45b0e55023a14821a12dd82ea9840bd3","b1cb099577114a63b1ce11cfd6244776","8b8728c5a343426694ee3a501caa6cbd","bd6bb7efcc9f4892b88253e2e3c63d58","570ddf72b5e8490aa747ef96ee0b4c32","3a5d1905c6374e53987e32e69d4a1cbf","364e8f4d5f544751a0b7d3e7e53ee3e5","a16956cc8a4948c98e801a86acfc3f9e"]},"id":"s3tuRXcX362-","executionInfo":{"status":"ok","timestamp":1670588559450,"user_tz":-540,"elapsed":645368,"user":{"displayName":"yoon-seop Lee","userId":"09698896171274086367"}},"outputId":"f8eb0625-a2b1-49dc-f9d1-ca87dc7f6bb6"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":[">> Split and Merage embeddings shape(Items x PLMs_dim) : (19035, 768)\n"]},{"output_type":"display_data","data":{"text/plain":["Batches:   0%|          | 0/595 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a3a487414d674d5c8d59d9482a854594"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":[">> Keywords embeddings shape(Items x PLMs_dim) : (19035, 768)\n"]}]},{"cell_type":"markdown","source":["## STEP 4. Semantic Search"],"metadata":{"id":"83xGulg5psDk"}},{"cell_type":"code","source":["# 3. Semantic documents search (Question-Answering)\n","my_query = \"Research about the Transformer network architecture, based solely on attention mechanisms.\"\n","\n","original_outputs, _ = sls.semantic_search(\n","    user_query = my_query,\n","    top_k = 10,\n","    index = all_index,\n","    print_results = True,\n","    )"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gvkyipij4Epq","executionInfo":{"status":"ok","timestamp":1670588559451,"user_tz":-540,"elapsed":8,"user":{"displayName":"yoon-seop Lee","userId":"09698896171274086367"}},"outputId":"60c49971-81e0-4bc8-e705-da659183dc18"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["\n"," === Calculate run time : 35.1307 ms === \n","\n",">> Your query : Research about the Transformer network architecture, based solely on attention mechanisms.\n","\n"," >> Top 1 - Paper Title : Area Attention  \n"," | Cluster : 32 \n"," | Extracted keywords : translation, nmt, generation, attention, bleu, language, english, text, sentences, dialogue, machine, nlg, neural, sequence, transformer, human, resource, korean, summarization, training \n"," | Year : 2019 \n"," | Abstract :   Existing attention mechanisms are trained to attend to individual items in a\n","collection (the memory) with a predefined, fixed granularity, e.g., a word\n","token or an image grid. We propose area attention: a way to attend to areas in\n","the memory, where each area contains a group of items that are structurally\n","adjacent, e.g., spatially for a 2D memory such as images, or temporally for a\n","1D memory such as natural language sentences. Importantly, the shape and the\n","size of an area are dynamically determined via learning, which enables a model\n","to attend to information with varying granularity. Area attention can easily\n","work with existing model architectures such as multi-head attention for\n","simultaneously attending to multiple areas in the memory. We evaluate area\n","attention on two tasks: neural machine translation (both character and\n","token-level) and image captioning, and improve upon strong (state-of-the-art)\n","baselines in all the cases. These improvements are obtainable with a basic form\n","of area attention that is parameter free.\n","\n","\n"," >> Top 2 - Paper Title : A Spiking Network that Learns to Extract Spike Signatures from Speech\n","  Signals  \n"," | Cluster : 35 \n"," | Extracted keywords : spiking, neuromorphic, spike, neuron, neurons, synaptic, neural, memristive, synapses, stdp, hardware, circuit, networks, computing, snn, coding, memristors, crossbar, snns, analog \n"," | Year : 2017 \n"," | Abstract :   Spiking neural networks (SNNs) with adaptive synapses reflect core properties\n","of biological neural networks. Speech recognition, as an application involving\n","audio coding and dynamic learning, provides a good test problem to study SNN\n","functionality. We present a simple, novel, and efficient nonrecurrent SNN that\n","learns to convert a speech signal into a spike train signature. The signature\n","is distinguishable from signatures for other speech signals representing\n","different words, thereby enabling digit recognition and discrimination in\n","devices that use only spiking neurons. The method uses a small, nonrecurrent\n","SNN consisting of Izhikevich neurons equipped with spike timing dependent\n","plasticity (STDP) and biologically realistic synapses. This approach introduces\n","an efficient and fast network without error-feedback training, although it does\n","require supervised training. The new simulation results produce discriminative\n","spike train patterns for spoken digits in which highly correlated spike trains\n","belong to the same category and low correlated patterns belong to different\n","categories. The proposed SNN is evaluated using a spoken digit recognition task\n","where a subset of the Aurora speech dataset is used. The experimental results\n","show that the network performs well in terms of accuracy rate and complexity.\n","\n","\n"," >> Top 3 - Paper Title : Learning in Memristive Neural Network Architectures using Analog\n","  Backpropagation Circuits  \n"," | Cluster : 35 \n"," | Extracted keywords : spiking, neuromorphic, spike, neuron, neurons, synaptic, neural, memristive, synapses, stdp, hardware, circuit, networks, computing, snn, coding, memristors, crossbar, snns, analog \n"," | Year : 2018 \n"," | Abstract :   The on-chip implementation of learning algorithms would speed-up the training\n","of neural networks in crossbar arrays. The circuit level design and\n","implementation of backpropagation algorithm using gradient descent operation\n","for neural network architectures is an open problem. In this paper, we proposed\n","the analog backpropagation learning circuits for various memristive learning\n","architectures, such as Deep Neural Network (DNN), Binary Neural Network (BNN),\n","Multiple Neural Network (MNN), Hierarchical Temporal Memory (HTM) and\n","Long-Short Term Memory (LSTM). The circuit design and verification is done\n","using TSMC 180nm CMOS process models, and TiO2 based memristor models. The\n","application level validations of the system are done using XOR problem, MNIST\n","character and Yale face image databases\n","\n","\n"," >> Top 4 - Paper Title : On-chip learning for domain wall synapse based Fully Connected Neural\n","  Network  \n"," | Cluster : 35 \n"," | Extracted keywords : spiking, neuromorphic, spike, neuron, neurons, synaptic, neural, memristive, synapses, stdp, hardware, circuit, networks, computing, snn, coding, memristors, crossbar, snns, analog \n"," | Year : 2019 \n"," | Abstract :   Spintronic devices are considered as promising candidates in implementing\n","neuromorphic systems or hardware neural networks, which are expected to perform\n","better than other existing computing systems for certain data classification\n","and regression tasks. In this paper, we have designed a feedforward Fully\n","Connected Neural Network (FCNN) with no hidden layer using spin orbit torque\n","driven domain wall devices as synapses and transistor based analog circuits as\n","neurons. A feedback circuit is also designed using transistors, which at every\n","iteration computes the change in weights of the synapses needed to train the\n","network using Stochastic Gradient Descent (SGD) method. Subsequently it sends\n","write current pulses to the domain wall based synaptic devices which move the\n","domain walls and updates the weights of the synapses. Through a combination of\n","micromagnetic simulations, analog circuit simulations and numerically solving\n","FCNN training equations, we demonstrate \"on-chip\" training of the designed FCNN\n","on the MNIST database of handwritten digits in this paper. We report the\n","training and test accuracies, energy consumed in the synaptic devices for the\n","training and possible issues with hardware implementation of FCNN that can\n","limit its test accuracy.\n","\n","\n"," >> Top 5 - Paper Title : Minimax Dynamics of Optimally Balanced Spiking Networks of Excitatory\n","  and Inhibitory Neurons  \n"," | Cluster : 35 \n"," | Extracted keywords : spiking, neuromorphic, spike, neuron, neurons, synaptic, neural, memristive, synapses, stdp, hardware, circuit, networks, computing, snn, coding, memristors, crossbar, snns, analog \n"," | Year : 2020 \n"," | Abstract :   Excitation-inhibition (E-I) balance is ubiquitously observed in the cortex.\n","Recent studies suggest an intriguing link between balance on fast timescales,\n","tight balance, and efficient information coding with spikes. We further this\n","connection by taking a principled approach to optimal balanced networks of\n","excitatory (E) and inhibitory (I) neurons. By deriving E-I spiking neural\n","networks from greedy spike-based optimizations of constrained minimax\n","objectives, we show that tight balance arises from correcting for deviations\n","from the minimax optima. We predict specific neuron firing rates in the network\n","by solving the minimax problem, going beyond statistical theories of balanced\n","networks. Finally, we design minimax objectives for reconstruction of an input\n","signal, associative memory, and storage of manifold attractors, and derive from\n","them E-I networks that perform the computation. Overall, we present a novel\n","normative modeling approach for spiking E-I networks, going beyond the\n","widely-used energy minimizing networks that violate Dale's law. Our networks\n","can be used to model cortical circuits and computations.\n","\n","\n"," >> Top 6 - Paper Title : Understanding Self-Attention of Self-Supervised Audio Transformers  \n"," | Cluster : 478 \n"," | Extracted keywords : speech, asr, relevance, recognition, acoustic, pronunciation, weighting, utterances, words, automatic, word, e2e, importance, baseline, named, fst, context, rescoring, filterbank, dataset \n"," | Year : 2020 \n"," | Abstract :   Self-supervised Audio Transformers (SAT) enable great success in many\n","downstream speech applications like ASR, but how they work has not been widely\n","explored yet. In this work, we present multiple strategies for the analysis of\n","attention mechanisms in SAT. We categorize attentions into explainable\n","categories, where we discover each category possesses its own unique\n","functionality. We provide a visualization tool for understanding multi-head\n","self-attention, importance ranking strategies for identifying critical\n","attention, and attention refinement techniques to improve model performance.\n","\n","\n"," >> Top 7 - Paper Title : Continuous Learning in a Single-Incremental-Task Scenario with Spike\n","  Features  \n"," | Cluster : 643 \n"," | Extracted keywords : forgetting, htm, temporal, retina, neuronal, catastrophic, neuroprosthesis, synapses, spikes, brain, _overlap, stimulus, visual, hardware, scenes, information, 256, intervals, freezing, working \n"," | Year : 2020 \n"," | Abstract :   Deep Neural Networks (DNNs) have two key deficiencies, their dependence on\n","high precision computing and their inability to perform sequential learning,\n","that is, when a DNN is trained on a first task and the same DNN is trained on\n","the next task it forgets the first task. This phenomenon of forgetting previous\n","tasks is also referred to as catastrophic forgetting. On the other hand a\n","mammalian brain outperforms DNNs in terms of energy efficiency and the ability\n","to learn sequentially without catastrophically forgetting. Here, we use\n","bio-inspired Spike Timing Dependent Plasticity (STDP)in the feature extraction\n","layers of the network with instantaneous neurons to extract meaningful\n","features. In the classification sections of the network we use a modified\n","synaptic intelligence that we refer to as cost per synapse metric as a\n","regularizer to immunize the network against catastrophic forgetting in a\n","Single-Incremental-Task scenario (SIT). In this study, we use MNIST handwritten\n","digits dataset that was divided into five sub-tasks.\n","\n","\n"," >> Top 8 - Paper Title : Additive function approximation in the brain  \n"," | Cluster : 1122 \n"," | Extracted keywords : stimulus, neurons, single, neuronal, trials, balanced, memories, items, response, hippocampus, networks, winner, responses, additive, permit, correct, separation, stimuli, synaptic, simulated \n"," | Year : 2019 \n"," | Abstract :   Many biological learning systems such as the mushroom body, hippocampus, and\n","cerebellum are built from sparsely connected networks of neurons. For a new\n","understanding of such networks, we study the function spaces induced by sparse\n","random features and characterize what functions may and may not be learned. A\n","network with $d$ inputs per neuron is found to be equivalent to an additive\n","model of order $d$, whereas with a degree distribution the network combines\n","additive terms of different orders. We identify three specific advantages of\n","sparsity: additive function approximation is a powerful inductive bias that\n","limits the curse of dimensionality, sparse networks are stable to outlier noise\n","in the inputs, and sparse random features are scalable. Thus, even simple brain\n","architectures can be powerful function approximators. Finally, we hope that\n","this work helps popularize kernel theories of networks among computational\n","neuroscientists.\n","\n","\n"," >> Top 9 - Paper Title : Emergence of grid-like representations by training recurrent neural\n","  networks to perform spatial localization  \n"," | Cluster : -1 \n"," | Extracted keywords : problem, algorithm, paper, results, using, study, method, used, time, approach, based, analysis, systems, new, use, proposed, different, function, set, present \n"," | Year : 2018 \n"," | Abstract :   Decades of research on the neural code underlying spatial navigation have\n","revealed a diverse set of neural response properties. The Entorhinal Cortex\n","(EC) of the mammalian brain contains a rich set of spatial correlates,\n","including grid cells which encode space using tessellating patterns. However,\n","the mechanisms and functional significance of these spatial representations\n","remain largely mysterious. As a new way to understand these neural\n","representations, we trained recurrent neural networks (RNNs) to perform\n","navigation tasks in 2D arenas based on velocity inputs. Surprisingly, we find\n","that grid-like spatial response patterns emerge in trained networks, along with\n","units that exhibit other spatial correlates, including border cells and\n","band-like cells. All these different functional types of neurons have been\n","observed experimentally. The order of the emergence of grid-like and border\n","cells is also consistent with observations from developmental studies.\n","Together, our results suggest that grid cells, border cells and others as\n","observed in EC may be a natural solution for representing space efficiently\n","given the predominant recurrent connections in the neural circuits.\n","\n","\n"," >> Top 10 - Paper Title : Network neuroscience for optimizing brain-computer interfaces  \n"," | Cluster : -1 \n"," | Extracted keywords : problem, algorithm, paper, results, using, study, method, used, time, approach, based, analysis, systems, new, use, proposed, different, function, set, present \n"," | Year : 2019 \n"," | Abstract :   Human-machine interactions are being increasingly explored to create\n","alternative ways of communication and to improve our daily life. Based on a\n","classification of the user's intention from the user's underlying neural\n","activity, brain-computer interfaces (BCIs) allow direct interactions with the\n","external environment while bypassing the traditional effector of the\n","musculoskeletal system. Despite the enormous potential of BCIs, there are still\n","a number of challenges that limit their societal impact, ranging from the\n","correct decoding of a human's thoughts, to the application of effective\n","learning strategies. Despite several important engineering advances, the basic\n","neuroscience behind these challenges remains poorly explored. Indeed, BCIs\n","involve complex dynamic changes related to neural plasticity at a diverse range\n","of spatiotemporal scales. One promising antidote to this complexity lies in\n","network science, which provides a natural language in which to model the\n","organizational principles of brain architecture and function as manifest in its\n","interconnectivity. Here, we briefly review the main limitations currently\n","affecting BCIs, and we offer our perspective on how they can be addressed by\n","means of network theoretic approaches. We posit that the emerging field of\n","network neuroscience will prove to be an effective tool to unlock human-machine\n","interactions.\n","\n"]}]}]}
